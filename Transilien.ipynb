{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transilien - Challenge Data\n",
    "\n",
    "## 1. EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "if not os.path.exists(\"results/\"):\n",
    "    os.makedirs(\"results\")\n",
    "SOURCES_DIR = \"sources/\"\n",
    "\n",
    "# TRAINING SET\n",
    "X = pd.read_csv(SOURCES_DIR + \"x_train_final.csv\")\n",
    "\n",
    "Y = pd.read_csv(SOURCES_DIR + \"y_train_final.csv\")\n",
    "# EVAL SET \n",
    "#X_Eval = pd.read_csv(SOURCES_DIR + \"x_test_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe complete dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X,Y], axis=1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir qu'il y a trois colonnes inutile ```'Unnamed: 0.1', 'Unnamed: 0','Unnamed: 0'``` que l'on peut supprimer et on peut renommer notre cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\"], inplace=True)\n",
    "Y.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "Y.rename(columns={\"p0q0\": \"Target\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X,Y], axis=1).describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous noterons TA le temps d'attente\n",
    "\n",
    "Nous noterons k le train dont nous souhaitons savoir le TA\n",
    "\n",
    "Nous noterons s la gare a laquelle le TA de k est estimé\n",
    "\n",
    "\n",
    "\n",
    "- train:  ID du train\n",
    "- gare:   ID de gare\n",
    "- date:   date\n",
    "- arret:  num arret [8-12]\n",
    "- p2q0:   Le TA de k a -2 gare\n",
    "- p3q0:   Le TA de k a -3 gare\n",
    "- p4q0:   Le TA de k a -4 gare\n",
    "- p0q2:   Le TA du train -2 a s\n",
    "- p0q3:   Le TA du train -3 a s\n",
    "- p0q4:   Le TA du train -4 a s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos features peuvent se separer en plusieurs catégories, les variables catégorielles comme ```train``` et ```gare```, une variable temporelle ```date``` et des variables numériques `arret`, `p2q0`, `p3q0`, `p4q0`, `p0q2`, `p0q3` et `p0q4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Etude des variables numériques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arret` est la variable qui répresente la position du train dans son trajet, cette valeur n'est pas une mesure, elle ne permet pas d'en tirer de l'information, deux trains peuvent être à leur arrêt n°3 sans être dans la même gare ou même la même ligne.\n",
    "L'utilisation de cette variable pour entrainer notre modèle est donc inutile.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables de type pXqY représente la différence entre le temps réél et le temps prévu de différents trains à différentes gares, ce sont des variables numériques qui peuvent être utilisé pour notre modèle.\n",
    "Pour les utiliser il faut d'abord les nettoyer (valeurs abérentes) et les standardiser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# études des valeurs abérrentes\n",
    "numCols = [\"p2q0\", \"p3q0\",\"p4q0\", \"p0q2\", \"p0q3\", \"p0q4\"]\n",
    "num_df = X[numCols]\n",
    "df = pd.concat([num_df,Y], axis=1)\n",
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que deux de nos features comportent des valeurs très inferieurs aux autres, même si ces valeurs peuvent être valide logiquement elles ne représentent pas un phénomène assez récurent pour les inclure dans notre dataset d'entrainement.\n",
    "On peut mettre une valeur minimum pour ces variables, ici on peut choisir -200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df > -200).all(axis=1)]\n",
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# étude du tailness (queue de distribution)\n",
    "df.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribution de chacune des features est semblable à la distribution de notre target, on peut donc dire que le traitement des features est donc acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[(X[numCols] > -200).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Etudes de la variable temporelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison entre les dates du set d'entrainement et du set de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = pd.read_csv(SOURCES_DIR + \"x_test_final.csv\").drop(columns=['Unnamed: 0'])\n",
    "#print(f'Minimum date X:{X['date'].min()}, Maximum date X:{X[\"date\"].max()}')\n",
    "#print(f'Minimum date X eval:{x_eval['date'].min()}, Maximum date X eval:{x_eval[\"date\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que les données du dataset d'entrainement (X) commencent en Avril 2023 et finissent en Novembre 2023 alors que les données de test commencent en Novembre 2023 et finissent en décembre 2023.\n",
    "Nous ne pouvons donc pas utiliser cette feature pour en détérminer d'autres comme la saisonalité, la température ou la météo car ces paramètres ne sont pas comparables entre nos données d'entrainement et de test (la météo par exemple n'est vraiment pas la même en décembre que en juin).\n",
    "Nous pourrons peut-être utilisé la date comme repère au sein d'une semaine lors du feature engineering\n",
    "\n",
    "A noter que comme l'ordre des données est important il faudra le prendre en compte lors de la séparation de notre dataset en X_train X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Etude des variables catégorielles\n",
    "\n",
    "Les variables catégorielles ne peuvent pas vraiment être utilisés pour entrainer notre modèle.\n",
    "\n",
    "Nous verrons lors du feature engineering si nous pouvons en tirer des informations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Premier entrainement\n",
    "\n",
    "Pour tester nos données et se faire une première idée nous pouvons tester nos données sur un Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns)\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "X['Target'] = Y[\"Target\"]\n",
    "X = X.sort_values(by='date')\n",
    "split_index = int(0.8 * len(X))\n",
    "target = X['Target']\n",
    "features = ['p2q0', 'p3q0', 'p4q0', 'p0q2', 'p0q3', 'p0q4']\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "Y_train, Y_test = target[:split_index], target[split_index:]\n",
    "#clf = RandomForestRegressor(n_estimators = 100, random_state = None,criterion='squared_error',oob_score=True,n_jobs=-1,max_depth=18,min_samples_leaf=5)\n",
    "clf = RandomForestClassifier(max_depth=18,n_estimators=20,  random_state=None, n_jobs=-1)\n",
    "clf.fit(X_train[features], Y_train)\n",
    "pred = clf.predict(X_test[features])\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "print(f'MAE Validation: {mae(Y_test, pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour améliorer notre score nous pouvons créer de nouvelles informations depuis nos features.\n",
    "\n",
    "> Ranking des gares\n",
    "\n",
    "Nous pouvons identifier chaque gare par son ID et la placer dans le trajet d'un train grâce au numéro d'arret. Cela nous permet de savoir quelle est la gare suivante ou précédente et donc de représenter nos gares par un graph et d'en tirer plus d'information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import networkx as nx\n",
    "sub_graphs = {}\n",
    "X['date'] = pd.to_datetime(X['date'])\n",
    " \n",
    "for day,group_day in X.groupby('date') :\n",
    "    sub_G = nx.DiGraph()\n",
    "    for _,group_train in group_day.groupby('train'):\n",
    "        \n",
    "        group_train = group_train.sort_values('arret')\n",
    "        gare = group_train.gare.values\n",
    "        stops = group_train.arret.values\n",
    "        delays = group_train.p0q2.values\n",
    "        edges = [(gare[i],gare[i+1]) for i in range(len(gare) -1) if stops[i+1] == stops[i] + 1]\n",
    "        sub_G.add_edges_from(edges)\n",
    " \n",
    "        for i in range(len(edges)):\n",
    "            try :\n",
    "                delay = sub_G.edges[edges[i]]['delay']\n",
    "                count = sub_G.edges[edges[i]]['count']\n",
    "                nx.set_edge_attributes(sub_G,{edges[i]: {'delay' : delay + delays[i+1],'count' : count + 1}})\n",
    "            except:\n",
    "                nx.set_edge_attributes(sub_G,{edges[i]: {'delay' : delays[i+1],'count' : 1}})\n",
    "    sub_graphs[str(day.date())] = copy.deepcopy(sub_G)\n",
    " \n",
    "G = nx.DiGraph()\n",
    "for g in sub_graphs.values():\n",
    "    G = nx.compose(G,g)\n",
    " \n",
    "edge_data = {}\n",
    "for e in G.edges:\n",
    "    edge_data[e] = {'delay':0,'count':0}\n",
    "    for g in sub_graphs.values():\n",
    "        if e in g.edges :\n",
    "            edge_data[e]['delay'] = edge_data[e]['delay'] + g.edges[e]['delay']\n",
    "            edge_data[e]['count'] = edge_data[e]['count'] + g.edges[e]['count']\n",
    " \n",
    "nx.set_edge_attributes(G,edge_data)\n",
    "del edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigen Centrality\n",
    "\n",
    "La centralité représente la place de notre gare dans notre graph, cette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_df = pd.DataFrame.from_dict(nx.eigenvector_centrality(G, weight=\"count\", max_iter=1000), orient='index', columns=['centrality']).reset_index(names='gare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbor_delay_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the mean delay for each node\n",
    "node_mean_delay = {}\n",
    "\n",
    "# Iterate over each node in the graph\n",
    "for node in G.nodes:\n",
    "    total_delay = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    # Iterate over all neighbors of the node (both incoming and outgoing edges)\n",
    "    for neighbor in G.neighbors(node):\n",
    "        # Get the edge between the node and its neighbor\n",
    "        edge_data = G.get_edge_data(node, neighbor)\n",
    "        \n",
    "        # Calculate the weighted delay for this edge (delay * count)\n",
    "        delay = edge_data[\"delay\"]  # delay attribute\n",
    "        count = edge_data[\"count\"]  # count attribute\n",
    "        \n",
    "        # Sum the delays and counts to compute the weighted mean\n",
    "        total_delay += delay * count\n",
    "        total_count += count\n",
    "    \n",
    "    # If there are neighbors, calculate the weighted mean delay for the node\n",
    "    if total_count > 0:\n",
    "        node_mean_delay[node] = total_delay / total_count\n",
    "    else:\n",
    "        node_mean_delay[node] = 0  # If no neighbors, set delay to 0\n",
    "\n",
    "# Output the weighted mean delays for each node\n",
    "neighbor_delay_df = pd.DataFrame.from_dict(node_mean_delay, orient='index', columns=['neighbor_delay']).reset_index(names='gare')\n",
    "neighbor_delay_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "dim = 32\n",
    "node2vec = Node2Vec(G, dimensions=dim, walk_length=20, num_walks=400, workers=1, seed=42)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)  # Train Word2Vec model\n",
    "nodes = list(G.nodes())  # Get node list\n",
    "embeddings = np.array([model.wv[node] for node in nodes])  # Retrieve embeddings\n",
    "n2v_df = pd.DataFrame(embeddings, index=nodes)\n",
    "n2v_df.index.name = \"gare\"\n",
    "n2v_df.columns = [f\"n2v_dim_{i}\" for i in range(embeddings.shape[1])]\n",
    "n2v_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df = pd.DataFrame(list(nx.pagerank(G).items()), columns=[\"gare\", \"PageRank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features to dataframe\n",
    "X = pd.merge(X, centrality_df, on=\"gare\")\n",
    "X = pd.merge(X, neighbor_delay_df, on='gare')\n",
    "X = pd.merge(X, pr_df, on=\"gare\")\n",
    "X.columns\n",
    "X_save = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(X, n2v_df, on=\"gare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('sources/x_train_post_engineering.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nouvelles Features:\n",
    "- Centrality: Représente la centralité d'une gare au sein du réseau\n",
    "- neighbor_delay:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.A Neural Network Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "# Vars\n",
    "dim = 32\n",
    "\n",
    "# MODEL\n",
    "class mainModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(mainModel,self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(256,activation = 'relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(128,activation = 'relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(64,activation = 'relu')\n",
    "        self.dense4 = tf.keras.layers.Dense(32,activation = 'relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(1,activation = 'linear')\n",
    "    \n",
    "    def get_dense(self,X):\n",
    "        X = self.dense1(X)\n",
    "        X = self.dense2(X)\n",
    "        X = self.dense3(X)\n",
    "        X = self.dense4(X)\n",
    "        return X\n",
    " \n",
    "    def call(self,X):\n",
    "        X = self.get_dense(X)\n",
    "        X = self.output_layer(X)\n",
    "        return X\n",
    "    \n",
    "# CALLBACKS\n",
    "class MAECallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "        mae_score = mae(self.y_val, y_pred)\n",
    "        mlflow.log_metric(\"MAE\", mae_score, step=epoch)\n",
    " \n",
    "# DATA\n",
    "X = pd.read_csv(\"sources/x_train_post_engineering.csv\")\n",
    "Y = pd.read_csv(SOURCES_DIR + \"y_train_final.csv\")\n",
    "X = X.sort_values(by='date')\n",
    "split_index = int(0.8 * len(X))\n",
    "target = X['Target']\n",
    "features = ['arret','p2q0', 'p3q0', 'p4q0', 'p0q2', 'p0q3', 'p0q4', 'centrality', 'neighbor_delay', 'PageRank']\n",
    "for x in range(dim):\n",
    "    features.append(f\"n2v_dim_{x}\")\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "Y_train, Y_test = target[:split_index], target[split_index:]\n",
    "X_train.loc[:, features] = (X_train[features] - X_train[features].mean()) / X_train[features].std()\n",
    "X_test.loc[:, features] = (X_test[features] - X_test[features].mean()) / X_test[features].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "use_mlflow = False\n",
    "num_epochs = 10\n",
    "batch_size = 1000\n",
    "model = mainModel()\n",
    "if use_mlflow:\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    mlflow.set_experiment(\"Embedding Neural Network\")\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"Number of layer\", len(model.layers))\n",
    "        model.compile(optimizer='adamax',\n",
    "                    loss= 'mae',\n",
    "                    metrics=[])\n",
    "        model.fit(X_train[features].values, Y_train.values, \n",
    "                validation_data=(X_test[features], Y_test),\n",
    "                epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                callbacks=[MAECallback(X_test[features], Y_test)])\n",
    "        embedded_layer = model.get_dense(X_train[features].values)\n",
    "else:\n",
    "    model.compile(optimizer='adamax',\n",
    "                    loss= 'mae',\n",
    "                    metrics=[])\n",
    "    model.fit(X_train[features].values, Y_train.values, \n",
    "                validation_data=(X_test[features], Y_test),\n",
    "                epochs=num_epochs,\n",
    "                batch_size=batch_size)\n",
    "    embedded_layer = model.get_dense(X_train[features].values)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.B KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=128, weights='distance')\n",
    "neigh.fit(embedded_layer, Y_train)\n",
    "pred = neigh.predict(model.get_dense(X_test[features]))\n",
    "\n",
    "mae(Y_test, pred)\n",
    "#0.6349923568024458\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = pd.read_csv(SOURCES_DIR + \"x_test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_eval = pd.merge(x_eval, centrality_df, on=\"gare\")\n",
    "x_eval = pd.merge(x_eval, neighbor_delay_df, on='gare')\n",
    "x_eval = pd.merge(x_eval, pr_df, on=\"gare\")\n",
    "x_eval = pd.merge(x_eval, n2v_df, on=\"gare\")\n",
    "x_eval = (x_eval[features] - x_eval[features].mean())/x_eval[features].std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prediction = neigh.predict(model.get_dense(x_eval[features]))\n",
    "prediction = pd.DataFrame(eval_prediction, columns=['p0q0']).to_csv('results/predictionKNN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.C RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_post_FE = RandomForestClassifier(max_depth=18,n_estimators=120, random_state=42, n_jobs=-1, min_samples_split=10, max_features=int(0.3*len(features)))\n",
    "clf_post_FE.fit(embedded_layer, Y_train)\n",
    "pred = clf_post_FE.predict(model.get_dense(X_test[features].values))\n",
    "print(f'MAE Validation: {mae(Y_test, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest Classifier post engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "X = X.sort_values(by='date')\n",
    "split_index = int(0.8 * len(X))\n",
    "target = X['Target']\n",
    "features = ['arret','p2q0', 'p3q0', 'p4q0', 'p0q2', 'p0q3', 'p0q4', 'centrality', 'neighbor_delay', 'PageRank']\n",
    "for x in range(dim):\n",
    "    features.append(f\"n2v_dim_{x}\")\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "Y_train, Y_test = target[:split_index], target[split_index:]\n",
    "#clf_post_FE = RandomForestRegressor(n_estimators = 100, random_state = None,criterion='squared_error',oob_score=True,n_jobs=-1,max_depth=18,min_samples_leaf=5)\n",
    "clf_post_FE = RandomForestClassifier(max_depth=18,n_estimators=120, random_state=42, n_jobs=-1, min_samples_split=10, max_features=int(0.3*len(features)))\n",
    "clf_post_FE.fit(X_train[features], Y_train)\n",
    "pred = clf_post_FE.predict(X_test[features])\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "print(f'MAE Validation: {mae(Y_test, pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = pd.read_csv(SOURCES_DIR + \"x_test_final.csv\").drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = pd.merge(x_eval, centrality_df, on=\"gare\")\n",
    "x_eval = pd.merge(x_eval, neighbor_delay_df, on='gare')\n",
    "x_eval = pd.merge(x_eval, pr_df, on=\"gare\")\n",
    "x_eval = pd.merge(x_eval, n2v_df, on=\"gare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prediction = clf_post_FE.predict(x_eval[features])\n",
    "prediction = pd.DataFrame(eval_prediction, columns=['p0q0']).to_csv('results/predictionRFC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meilleur score sur [challenge-data](https://challengedata.ens.fr/): \n",
    "> GraphicCardEater : 0.6658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"End of notebook!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recherche d'un autre modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"sources/x_train_post_engineering.csv\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.sort_values(by='date')\n",
    "split_index = int(0.8 * len(X))\n",
    "target = X['Target']\n",
    "features = ['arret','p2q0', 'p3q0', 'p4q0', 'p0q2', 'p0q3', 'p0q4', 'centrality', 'neighbor_delay', 'PageRank']\n",
    "for x in range(dim):\n",
    "    features.append(f\"n2v_dim_{x}\")\n",
    "#features = ['arret','p2q0', 'p3q0', 'p4q0', 'p0q2', 'p0q3', 'p0q4']\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "Y_train, Y_test = target[:split_index], target[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_r = xgb.XGBRegressor(objective ='reg:squarederror', \n",
    "                  n_estimators = 120, seed = 42) \n",
    "\n",
    "xgb_r.fit(X_train[features], Y_train) \n",
    "# Predict the model \n",
    "xgb_pred = xgb_r.predict(X_test[features])\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "print(f'MAE Validation: {mae(Y_test, xgb_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train[features], Y_train)\n",
    "gbr_pred = model.predict(X_test[features])\n",
    "print(f'MAE Validation: {mae(Y_test, gbr_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=6, random_state=0, n_init=\"auto\").fit(X_train[features])\n",
    "kmeans.predict(X_test[features])\n",
    "kmeans.cluster_centers_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
