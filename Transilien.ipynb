{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transilien - Challenge Data\n",
    "\n",
    "## 1. EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "if not os.path.exists(\"results/\"):\n",
    "    os.makedirs(\"results\")\n",
    "SOURCES_DIR = \"sources/\"\n",
    "\n",
    "# TRAINING SET\n",
    "X = pd.read_csv(SOURCES_DIR + \"x_train_final.csv\")\n",
    "\n",
    "Y = pd.read_csv(SOURCES_DIR + \"y_train_final.csv\")\n",
    "# EVAL SET \n",
    "#X_Eval = pd.read_csv(SOURCES_DIR + \"x_test_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe complete dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'train', 'gare', 'date', 'arret', 'p2q0',\n",
       "       'p3q0', 'p4q0', 'p0q2', 'p0q3', 'p0q4', 'Unnamed: 0', 'p0q0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X,Y], axis=1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir qu'il y a trois colonnes inutile ```'Unnamed: 0.1', 'Unnamed: 0','Unnamed: 0'``` que l'on peut supprimer et on peut renommer notre cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\"], inplace=True)\n",
    "Y.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "Y.rename(columns={\"p0q0\": \"Target\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>gare</th>\n",
       "      <th>date</th>\n",
       "      <th>arret</th>\n",
       "      <th>p2q0</th>\n",
       "      <th>p3q0</th>\n",
       "      <th>p4q0</th>\n",
       "      <th>p0q2</th>\n",
       "      <th>p0q3</th>\n",
       "      <th>p0q4</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>667264</td>\n",
       "      <td>667264</td>\n",
       "      <td>667264</td>\n",
       "      <td>667264.000000</td>\n",
       "      <td>667264.000000</td>\n",
       "      <td>667264.000000</td>\n",
       "      <td>667264.000000</td>\n",
       "      <td>667264.000000</td>\n",
       "      <td>667264.000000</td>\n",
       "      <td>667264.000000</td>\n",
       "      <td>667264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>37544</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>PBYUMJ</td>\n",
       "      <td>JLR</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>50</td>\n",
       "      <td>31643</td>\n",
       "      <td>8417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.277499</td>\n",
       "      <td>-0.170696</td>\n",
       "      <td>-0.167304</td>\n",
       "      <td>-0.176308</td>\n",
       "      <td>-0.163223</td>\n",
       "      <td>-0.173579</td>\n",
       "      <td>-0.174436</td>\n",
       "      <td>-0.159950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.030424</td>\n",
       "      <td>1.976521</td>\n",
       "      <td>1.960416</td>\n",
       "      <td>1.926275</td>\n",
       "      <td>1.988527</td>\n",
       "      <td>2.643148</td>\n",
       "      <td>4.732999</td>\n",
       "      <td>1.987872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-160.000000</td>\n",
       "      <td>-160.000000</td>\n",
       "      <td>-160.000000</td>\n",
       "      <td>-160.000000</td>\n",
       "      <td>-1441.000000</td>\n",
       "      <td>-1441.000000</td>\n",
       "      <td>-160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train    gare        date          arret           p2q0  \\\n",
       "count   667264  667264      667264  667264.000000  667264.000000   \n",
       "unique   37544      84          91            NaN            NaN   \n",
       "top     PBYUMJ     JLR  2023-05-16            NaN            NaN   \n",
       "freq        50   31643        8417            NaN            NaN   \n",
       "mean       NaN     NaN         NaN      18.277499      -0.170696   \n",
       "std        NaN     NaN         NaN       7.030424       1.976521   \n",
       "min        NaN     NaN         NaN       7.000000    -160.000000   \n",
       "25%        NaN     NaN         NaN      12.000000      -1.000000   \n",
       "50%        NaN     NaN         NaN      18.000000       0.000000   \n",
       "75%        NaN     NaN         NaN      24.000000       1.000000   \n",
       "max        NaN     NaN         NaN      42.000000      14.000000   \n",
       "\n",
       "                 p3q0           p4q0           p0q2           p0q3  \\\n",
       "count   667264.000000  667264.000000  667264.000000  667264.000000   \n",
       "unique            NaN            NaN            NaN            NaN   \n",
       "top               NaN            NaN            NaN            NaN   \n",
       "freq              NaN            NaN            NaN            NaN   \n",
       "mean        -0.167304      -0.176308      -0.163223      -0.173579   \n",
       "std          1.960416       1.926275       1.988527       2.643148   \n",
       "min       -160.000000    -160.000000    -160.000000   -1441.000000   \n",
       "25%         -1.000000      -1.000000      -1.000000      -1.000000   \n",
       "50%          0.000000       0.000000       0.000000       0.000000   \n",
       "75%          1.000000       1.000000       1.000000       1.000000   \n",
       "max         15.000000      15.000000      15.000000      15.000000   \n",
       "\n",
       "                 p0q4         Target  \n",
       "count   667264.000000  667264.000000  \n",
       "unique            NaN            NaN  \n",
       "top               NaN            NaN  \n",
       "freq              NaN            NaN  \n",
       "mean        -0.174436      -0.159950  \n",
       "std          4.732999       1.987872  \n",
       "min      -1441.000000    -160.000000  \n",
       "25%         -1.000000      -1.000000  \n",
       "50%          0.000000       0.000000  \n",
       "75%          1.000000       1.000000  \n",
       "max         15.000000      15.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X,Y], axis=1).describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous noterons TA le temps d'attente\n",
    "\n",
    "Nous noterons k le train dont nous souhaitons savoir le TA\n",
    "\n",
    "Nous noterons s la gare a laquelle le TA de k est estimé\n",
    "\n",
    "\n",
    "\n",
    "- train:  ID du train\n",
    "- gare:   ID de gare\n",
    "- date:   date\n",
    "- arret:  num arret [8-12]\n",
    "- p2q0:   Le TA de k a -2 gare\n",
    "- p3q0:   Le TA de k a -3 gare\n",
    "- p4q0:   Le TA de k a -4 gare\n",
    "- p0q2:   Le TA du train -2 a s\n",
    "- p0q3:   Le TA du train -3 a s\n",
    "- p0q4:   Le TA du train -4 a s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train     object\n",
       "gare      object\n",
       "date      object\n",
       "arret      int64\n",
       "p2q0     float64\n",
       "p3q0     float64\n",
       "p4q0     float64\n",
       "p0q2     float64\n",
       "p0q3     float64\n",
       "p0q4     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos features peuvent se separer en plusieurs catégories, les variables catégorielles comme ```train``` et ```gare```, une variable temporelle ```date``` et des variables numériques `arret`, `p2q0`, `p3q0`, `p4q0`, `p0q2`, `p0q3` et `p0q4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Etude des variables numériques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arret` est la variable qui répresente la position du train dans son trajet, cette valeur n'est pas une mesure, elle ne permet pas d'en tirer de l'information, deux trains peuvent être à leur arrêt n°3 sans être dans la même gare ou même la même ligne.\n",
    "L'utilisation de cette variable pour entrainer notre modèle est donc inutile.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables de type pXqY représente la différence entre le temps réél et le temps prévu de différents trains à différentes gares, ce sont des variables numériques qui peuvent être utilisé pour notre modèle.\n",
    "Pour les utiliser il faut d'abord les nettoyer (valeurs abérentes) et les standardiser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# études des valeurs abérrentes\n",
    "numCols = [\"p2q0\", \"p3q0\",\"p4q0\", \"p0q2\", \"p0q3\", \"p0q4\"]\n",
    "num_df = X[numCols]\n",
    "df = pd.concat([num_df,Y], axis=1)\n",
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que deux de nos features comportent des valeurs très inferieurs aux autres, même si ces valeurs peuvent être valide logiquement elles ne représentent pas un phénomène assez récurent pour les inclure dans notre dataset d'entrainement.\n",
    "On peut mettre une valeur minimum pour ces variables, ici on peut choisir -200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df > -200).all(axis=1)]\n",
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p2q0       970.072810\n",
       "p3q0       992.575043\n",
       "p4q0      1029.175404\n",
       "p0q2       921.910824\n",
       "p0q3       850.161169\n",
       "p0q4       744.363971\n",
       "Target     869.678216\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# étude du tailness (queue de distribution)\n",
    "df.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribution de chacune des features est semblable à la distribution de notre target, on peut donc dire que le traitement des features est donc acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[(X[numCols] > -200).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Etudes de la variable temporelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison entre les dates du set d'entrainement et du set de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = pd.read_csv(SOURCES_DIR + \"x_test_final.csv\").drop(columns=['Unnamed: 0'])\n",
    "#print(f'Minimum date X:{X['date'].min()}, Maximum date X:{X[\"date\"].max()}')\n",
    "#print(f'Minimum date X eval:{x_eval['date'].min()}, Maximum date X eval:{x_eval[\"date\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que les données du dataset d'entrainement (X) commencent en Avril 2023 et finissent en Novembre 2023 alors que les données de test commencent en Novembre 2023 et finissent en décembre 2023.\n",
    "Nous ne pouvons donc pas utiliser cette feature pour en détérminer d'autres comme la saisonalité, la température ou la météo car ces paramètres ne sont pas comparables entre nos données d'entrainement et de test (la météo par exemple n'est vraiment pas la même en décembre que en juin).\n",
    "Nous pourrons peut-être utilisé la date comme repère au sein d'une semaine lors du feature engineering\n",
    "\n",
    "A noter que comme l'ordre des données est important il faudra le prendre en compte lors de la séparation de notre dataset en X_train X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Etude des variables catégorielles\n",
    "\n",
    "Les variables catégorielles ne peuvent pas vraiment être utilisés pour entrainer notre modèle.\n",
    "\n",
    "Nous verrons lors du feature engineering si nous pouvons en tirer des informations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Premier entrainement\n",
    "\n",
    "Pour tester nos données et se faire une première idée nous pouvons tester nos données sur un Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['train', 'gare', 'date', 'arret', 'p2q0', 'p3q0', 'p4q0', 'p0q2',\n",
      "       'p0q3', 'p0q4'],\n",
      "      dtype='object')\n",
      "MAE Validation: 0.7800707370440308\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "X['Target'] = Y[\"Target\"]\n",
    "X = X.sort_values(by='date')\n",
    "split_index = int(0.8 * len(X))\n",
    "target = X['Target']\n",
    "features = ['p2q0', 'p3q0', 'p4q0', 'p0q2', 'p0q3', 'p0q4']\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "Y_train, Y_test = target[:split_index], target[split_index:]\n",
    "#clf = RandomForestRegressor(n_estimators = 100, random_state = None,criterion='squared_error',oob_score=True,n_jobs=-1,max_depth=18,min_samples_leaf=5)\n",
    "clf = RandomForestClassifier(max_depth=18,n_estimators=20,  random_state=None, n_jobs=-1)\n",
    "clf.fit(X_train[features], Y_train)\n",
    "pred = clf.predict(X_test[features])\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "print(f'MAE Validation: {mae(Y_test, pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour améliorer notre score nous pouvons créer de nouvelles informations depuis nos features.\n",
    "\n",
    "> Ranking des gares\n",
    "\n",
    "Nous pouvons identifier chaque gare par son ID et la placer dans le trajet d'un train grâce au numéro d'arret. Cela nous permet de savoir quelle est la gare suivante ou précédente et donc de représenter nos gares par un graph et d'en tirer plus d'information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['train', 'gare', 'date', 'arret', 'p2q0', 'p3q0', 'p4q0', 'p0q2',\n",
       "       'p0q3', 'p0q4', 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import networkx as nx\n",
    "sub_graphs = {}\n",
    "X['date'] = pd.to_datetime(X['date'])\n",
    " \n",
    "for day,group_day in X.groupby('date') :\n",
    "    sub_G = nx.DiGraph()\n",
    "    for _,group_train in group_day.groupby('train'):\n",
    "        \n",
    "        group_train = group_train.sort_values('arret')\n",
    "        gare = group_train.gare.values\n",
    "        stops = group_train.arret.values\n",
    "        delays = group_train.p0q2.values\n",
    "        edges = [(gare[i],gare[i+1]) for i in range(len(gare) -1) if stops[i+1] == stops[i] + 1]\n",
    "        sub_G.add_edges_from(edges)\n",
    " \n",
    "        for i in range(len(edges)):\n",
    "            try :\n",
    "                delay = sub_G.edges[edges[i]]['delay']\n",
    "                count = sub_G.edges[edges[i]]['count']\n",
    "                nx.set_edge_attributes(sub_G,{edges[i]: {'delay' : delay + delays[i+1],'count' : count + 1}})\n",
    "            except:\n",
    "                nx.set_edge_attributes(sub_G,{edges[i]: {'delay' : delays[i+1],'count' : 1}})\n",
    "    sub_graphs[str(day.date())] = copy.deepcopy(sub_G)\n",
    " \n",
    "G = nx.DiGraph()\n",
    "for g in sub_graphs.values():\n",
    "    G = nx.compose(G,g)\n",
    " \n",
    "edge_data = {}\n",
    "for e in G.edges:\n",
    "    edge_data[e] = {'delay':0,'count':0}\n",
    "    for g in sub_graphs.values():\n",
    "        if e in g.edges :\n",
    "            edge_data[e]['delay'] = edge_data[e]['delay'] + g.edges[e]['delay']\n",
    "            edge_data[e]['count'] = edge_data[e]['count'] + g.edges[e]['count']\n",
    " \n",
    "nx.set_edge_attributes(G,edge_data)\n",
    "del edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigen Centrality\n",
    "\n",
    "La centralité représente la place de notre gare dans notre graph, cette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_df = pd.DataFrame.from_dict(nx.eigenvector_centrality(G, weight=\"count\", max_iter=1000), orient='index', columns=['centrality']).reset_index(names='gare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbor_delay_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty dictionary to store the mean delay for each node\n",
    "node_mean_delay = {}\n",
    "\n",
    "# Iterate over each node in the graph\n",
    "for node in G.nodes:\n",
    "    total_delay = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    # Iterate over all neighbors of the node (both incoming and outgoing edges)\n",
    "    for neighbor in G.neighbors(node):\n",
    "        # Get the edge between the node and its neighbor\n",
    "        edge_data = G.get_edge_data(node, neighbor)\n",
    "        \n",
    "        # Calculate the weighted delay for this edge (delay * count)\n",
    "        delay = edge_data[\"delay\"]  # delay attribute\n",
    "        count = edge_data[\"count\"]  # count attribute\n",
    "        \n",
    "        # Sum the delays and counts to compute the weighted mean\n",
    "        total_delay += delay * count\n",
    "        total_count += count\n",
    "    \n",
    "    # If there are neighbors, calculate the weighted mean delay for the node\n",
    "    if total_count > 0:\n",
    "        node_mean_delay[node] = total_delay / total_count\n",
    "    else:\n",
    "        node_mean_delay[node] = 0  # If no neighbors, set delay to 0\n",
    "\n",
    "# Output the weighted mean delays for each node\n",
    "neighbor_delay_df = pd.DataFrame.from_dict(node_mean_delay, orient='index', columns=['neighbor_delay']).reset_index(names='gare')\n",
    "neighbor_delay_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fa0c6622f6468fa8a99884307f5c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 400/400 [00:00<00:00, 537.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n2v_dim_0</th>\n",
       "      <th>n2v_dim_1</th>\n",
       "      <th>n2v_dim_2</th>\n",
       "      <th>n2v_dim_3</th>\n",
       "      <th>n2v_dim_4</th>\n",
       "      <th>n2v_dim_5</th>\n",
       "      <th>n2v_dim_6</th>\n",
       "      <th>n2v_dim_7</th>\n",
       "      <th>n2v_dim_8</th>\n",
       "      <th>n2v_dim_9</th>\n",
       "      <th>...</th>\n",
       "      <th>n2v_dim_22</th>\n",
       "      <th>n2v_dim_23</th>\n",
       "      <th>n2v_dim_24</th>\n",
       "      <th>n2v_dim_25</th>\n",
       "      <th>n2v_dim_26</th>\n",
       "      <th>n2v_dim_27</th>\n",
       "      <th>n2v_dim_28</th>\n",
       "      <th>n2v_dim_29</th>\n",
       "      <th>n2v_dim_30</th>\n",
       "      <th>n2v_dim_31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gare</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OJA</th>\n",
       "      <td>0.507148</td>\n",
       "      <td>-0.471593</td>\n",
       "      <td>0.779702</td>\n",
       "      <td>-0.115934</td>\n",
       "      <td>-0.033448</td>\n",
       "      <td>-0.573742</td>\n",
       "      <td>-0.186358</td>\n",
       "      <td>0.103128</td>\n",
       "      <td>-0.284265</td>\n",
       "      <td>-0.005853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683856</td>\n",
       "      <td>0.554231</td>\n",
       "      <td>-0.102006</td>\n",
       "      <td>0.403273</td>\n",
       "      <td>-0.378941</td>\n",
       "      <td>-0.042145</td>\n",
       "      <td>0.322520</td>\n",
       "      <td>-0.175137</td>\n",
       "      <td>-0.336602</td>\n",
       "      <td>-0.343602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELZ</th>\n",
       "      <td>0.284330</td>\n",
       "      <td>-0.326405</td>\n",
       "      <td>0.774444</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>-0.059217</td>\n",
       "      <td>-0.301916</td>\n",
       "      <td>0.392247</td>\n",
       "      <td>0.034888</td>\n",
       "      <td>-0.205089</td>\n",
       "      <td>-0.046661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387644</td>\n",
       "      <td>0.206279</td>\n",
       "      <td>0.156247</td>\n",
       "      <td>0.541461</td>\n",
       "      <td>-0.198723</td>\n",
       "      <td>-0.321726</td>\n",
       "      <td>0.404683</td>\n",
       "      <td>-0.430902</td>\n",
       "      <td>-0.180803</td>\n",
       "      <td>-0.261840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZHN</th>\n",
       "      <td>0.228065</td>\n",
       "      <td>-0.316640</td>\n",
       "      <td>0.610269</td>\n",
       "      <td>-0.138866</td>\n",
       "      <td>0.134424</td>\n",
       "      <td>-0.082857</td>\n",
       "      <td>-0.248816</td>\n",
       "      <td>0.275596</td>\n",
       "      <td>-0.112945</td>\n",
       "      <td>-0.100075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548580</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>-0.098387</td>\n",
       "      <td>0.342281</td>\n",
       "      <td>-0.316335</td>\n",
       "      <td>-0.291533</td>\n",
       "      <td>0.220180</td>\n",
       "      <td>-0.585731</td>\n",
       "      <td>-0.086033</td>\n",
       "      <td>0.313226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYF</th>\n",
       "      <td>0.325646</td>\n",
       "      <td>-0.284495</td>\n",
       "      <td>0.568499</td>\n",
       "      <td>0.154657</td>\n",
       "      <td>0.270077</td>\n",
       "      <td>0.130563</td>\n",
       "      <td>-0.046279</td>\n",
       "      <td>0.191856</td>\n",
       "      <td>-0.005002</td>\n",
       "      <td>0.055153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323495</td>\n",
       "      <td>0.103825</td>\n",
       "      <td>-0.146756</td>\n",
       "      <td>0.353262</td>\n",
       "      <td>-0.244275</td>\n",
       "      <td>-0.288779</td>\n",
       "      <td>0.236510</td>\n",
       "      <td>-0.317321</td>\n",
       "      <td>-0.111585</td>\n",
       "      <td>0.133927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JLR</th>\n",
       "      <td>0.147026</td>\n",
       "      <td>0.068405</td>\n",
       "      <td>0.585476</td>\n",
       "      <td>-0.190671</td>\n",
       "      <td>0.285111</td>\n",
       "      <td>-0.099070</td>\n",
       "      <td>-0.010051</td>\n",
       "      <td>0.271686</td>\n",
       "      <td>0.038007</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246062</td>\n",
       "      <td>0.115026</td>\n",
       "      <td>-0.026862</td>\n",
       "      <td>0.512985</td>\n",
       "      <td>-0.157481</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0.245358</td>\n",
       "      <td>-0.450107</td>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.110520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n2v_dim_0  n2v_dim_1  n2v_dim_2  n2v_dim_3  n2v_dim_4  n2v_dim_5  \\\n",
       "gare                                                                     \n",
       "OJA    0.507148  -0.471593   0.779702  -0.115934  -0.033448  -0.573742   \n",
       "ELZ    0.284330  -0.326405   0.774444   0.060569  -0.059217  -0.301916   \n",
       "ZHN    0.228065  -0.316640   0.610269  -0.138866   0.134424  -0.082857   \n",
       "KYF    0.325646  -0.284495   0.568499   0.154657   0.270077   0.130563   \n",
       "JLR    0.147026   0.068405   0.585476  -0.190671   0.285111  -0.099070   \n",
       "\n",
       "      n2v_dim_6  n2v_dim_7  n2v_dim_8  n2v_dim_9  ...  n2v_dim_22  n2v_dim_23  \\\n",
       "gare                                              ...                           \n",
       "OJA   -0.186358   0.103128  -0.284265  -0.005853  ...    0.683856    0.554231   \n",
       "ELZ    0.392247   0.034888  -0.205089  -0.046661  ...    0.387644    0.206279   \n",
       "ZHN   -0.248816   0.275596  -0.112945  -0.100075  ...    0.548580    0.119403   \n",
       "KYF   -0.046279   0.191856  -0.005002   0.055153  ...    0.323495    0.103825   \n",
       "JLR   -0.010051   0.271686   0.038007  -0.002762  ...    0.246062    0.115026   \n",
       "\n",
       "      n2v_dim_24  n2v_dim_25  n2v_dim_26  n2v_dim_27  n2v_dim_28  n2v_dim_29  \\\n",
       "gare                                                                           \n",
       "OJA    -0.102006    0.403273   -0.378941   -0.042145    0.322520   -0.175137   \n",
       "ELZ     0.156247    0.541461   -0.198723   -0.321726    0.404683   -0.430902   \n",
       "ZHN    -0.098387    0.342281   -0.316335   -0.291533    0.220180   -0.585731   \n",
       "KYF    -0.146756    0.353262   -0.244275   -0.288779    0.236510   -0.317321   \n",
       "JLR    -0.026862    0.512985   -0.157481   -0.251940    0.245358   -0.450107   \n",
       "\n",
       "      n2v_dim_30  n2v_dim_31  \n",
       "gare                          \n",
       "OJA    -0.336602   -0.343602  \n",
       "ELZ    -0.180803   -0.261840  \n",
       "ZHN    -0.086033    0.313226  \n",
       "KYF    -0.111585    0.133927  \n",
       "JLR     0.019373    0.110520  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "dim = 32\n",
    "node2vec = Node2Vec(G, dimensions=dim, walk_length=20, num_walks=400, workers=1, seed=42)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)  # Train Word2Vec model\n",
    "nodes = list(G.nodes())  # Get node list\n",
    "embeddings = np.array([model.wv[node] for node in nodes])  # Retrieve embeddings\n",
    "n2v_df = pd.DataFrame(embeddings, index=nodes)\n",
    "n2v_df.index.name = \"gare\"\n",
    "n2v_df.columns = [f\"n2v_dim_{i}\" for i in range(embeddings.shape[1])]\n",
    "n2v_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n2v_dim_0</th>\n",
       "      <th>n2v_dim_1</th>\n",
       "      <th>n2v_dim_2</th>\n",
       "      <th>n2v_dim_3</th>\n",
       "      <th>n2v_dim_4</th>\n",
       "      <th>n2v_dim_5</th>\n",
       "      <th>n2v_dim_6</th>\n",
       "      <th>n2v_dim_7</th>\n",
       "      <th>n2v_dim_8</th>\n",
       "      <th>n2v_dim_9</th>\n",
       "      <th>...</th>\n",
       "      <th>n2v_dim_22</th>\n",
       "      <th>n2v_dim_23</th>\n",
       "      <th>n2v_dim_24</th>\n",
       "      <th>n2v_dim_25</th>\n",
       "      <th>n2v_dim_26</th>\n",
       "      <th>n2v_dim_27</th>\n",
       "      <th>n2v_dim_28</th>\n",
       "      <th>n2v_dim_29</th>\n",
       "      <th>n2v_dim_30</th>\n",
       "      <th>n2v_dim_31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gare</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OJA</th>\n",
       "      <td>0.507148</td>\n",
       "      <td>-0.471593</td>\n",
       "      <td>0.779702</td>\n",
       "      <td>-0.115934</td>\n",
       "      <td>-0.033448</td>\n",
       "      <td>-0.573742</td>\n",
       "      <td>-0.186358</td>\n",
       "      <td>0.103128</td>\n",
       "      <td>-0.284265</td>\n",
       "      <td>-0.005853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683856</td>\n",
       "      <td>0.554231</td>\n",
       "      <td>-0.102006</td>\n",
       "      <td>0.403273</td>\n",
       "      <td>-0.378941</td>\n",
       "      <td>-0.042145</td>\n",
       "      <td>0.322520</td>\n",
       "      <td>-0.175137</td>\n",
       "      <td>-0.336602</td>\n",
       "      <td>-0.343602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELZ</th>\n",
       "      <td>0.284330</td>\n",
       "      <td>-0.326405</td>\n",
       "      <td>0.774444</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>-0.059217</td>\n",
       "      <td>-0.301916</td>\n",
       "      <td>0.392247</td>\n",
       "      <td>0.034888</td>\n",
       "      <td>-0.205089</td>\n",
       "      <td>-0.046661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387644</td>\n",
       "      <td>0.206279</td>\n",
       "      <td>0.156247</td>\n",
       "      <td>0.541461</td>\n",
       "      <td>-0.198723</td>\n",
       "      <td>-0.321726</td>\n",
       "      <td>0.404683</td>\n",
       "      <td>-0.430902</td>\n",
       "      <td>-0.180803</td>\n",
       "      <td>-0.261840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZHN</th>\n",
       "      <td>0.228065</td>\n",
       "      <td>-0.316640</td>\n",
       "      <td>0.610269</td>\n",
       "      <td>-0.138866</td>\n",
       "      <td>0.134424</td>\n",
       "      <td>-0.082857</td>\n",
       "      <td>-0.248816</td>\n",
       "      <td>0.275596</td>\n",
       "      <td>-0.112945</td>\n",
       "      <td>-0.100075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548580</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>-0.098387</td>\n",
       "      <td>0.342281</td>\n",
       "      <td>-0.316335</td>\n",
       "      <td>-0.291533</td>\n",
       "      <td>0.220180</td>\n",
       "      <td>-0.585731</td>\n",
       "      <td>-0.086033</td>\n",
       "      <td>0.313226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KYF</th>\n",
       "      <td>0.325646</td>\n",
       "      <td>-0.284495</td>\n",
       "      <td>0.568499</td>\n",
       "      <td>0.154657</td>\n",
       "      <td>0.270077</td>\n",
       "      <td>0.130563</td>\n",
       "      <td>-0.046279</td>\n",
       "      <td>0.191856</td>\n",
       "      <td>-0.005002</td>\n",
       "      <td>0.055153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323495</td>\n",
       "      <td>0.103825</td>\n",
       "      <td>-0.146756</td>\n",
       "      <td>0.353262</td>\n",
       "      <td>-0.244275</td>\n",
       "      <td>-0.288779</td>\n",
       "      <td>0.236510</td>\n",
       "      <td>-0.317321</td>\n",
       "      <td>-0.111585</td>\n",
       "      <td>0.133927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JLR</th>\n",
       "      <td>0.147026</td>\n",
       "      <td>0.068405</td>\n",
       "      <td>0.585476</td>\n",
       "      <td>-0.190671</td>\n",
       "      <td>0.285111</td>\n",
       "      <td>-0.099070</td>\n",
       "      <td>-0.010051</td>\n",
       "      <td>0.271686</td>\n",
       "      <td>0.038007</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246062</td>\n",
       "      <td>0.115026</td>\n",
       "      <td>-0.026862</td>\n",
       "      <td>0.512985</td>\n",
       "      <td>-0.157481</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0.245358</td>\n",
       "      <td>-0.450107</td>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.110520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n2v_dim_0  n2v_dim_1  n2v_dim_2  n2v_dim_3  n2v_dim_4  n2v_dim_5  \\\n",
       "gare                                                                     \n",
       "OJA    0.507148  -0.471593   0.779702  -0.115934  -0.033448  -0.573742   \n",
       "ELZ    0.284330  -0.326405   0.774444   0.060569  -0.059217  -0.301916   \n",
       "ZHN    0.228065  -0.316640   0.610269  -0.138866   0.134424  -0.082857   \n",
       "KYF    0.325646  -0.284495   0.568499   0.154657   0.270077   0.130563   \n",
       "JLR    0.147026   0.068405   0.585476  -0.190671   0.285111  -0.099070   \n",
       "\n",
       "      n2v_dim_6  n2v_dim_7  n2v_dim_8  n2v_dim_9  ...  n2v_dim_22  n2v_dim_23  \\\n",
       "gare                                              ...                           \n",
       "OJA   -0.186358   0.103128  -0.284265  -0.005853  ...    0.683856    0.554231   \n",
       "ELZ    0.392247   0.034888  -0.205089  -0.046661  ...    0.387644    0.206279   \n",
       "ZHN   -0.248816   0.275596  -0.112945  -0.100075  ...    0.548580    0.119403   \n",
       "KYF   -0.046279   0.191856  -0.005002   0.055153  ...    0.323495    0.103825   \n",
       "JLR   -0.010051   0.271686   0.038007  -0.002762  ...    0.246062    0.115026   \n",
       "\n",
       "      n2v_dim_24  n2v_dim_25  n2v_dim_26  n2v_dim_27  n2v_dim_28  n2v_dim_29  \\\n",
       "gare                                                                           \n",
       "OJA    -0.102006    0.403273   -0.378941   -0.042145    0.322520   -0.175137   \n",
       "ELZ     0.156247    0.541461   -0.198723   -0.321726    0.404683   -0.430902   \n",
       "ZHN    -0.098387    0.342281   -0.316335   -0.291533    0.220180   -0.585731   \n",
       "KYF    -0.146756    0.353262   -0.244275   -0.288779    0.236510   -0.317321   \n",
       "JLR    -0.026862    0.512985   -0.157481   -0.251940    0.245358   -0.450107   \n",
       "\n",
       "      n2v_dim_30  n2v_dim_31  \n",
       "gare                          \n",
       "OJA    -0.336602   -0.343602  \n",
       "ELZ    -0.180803   -0.261840  \n",
       "ZHN    -0.086033    0.313226  \n",
       "KYF    -0.111585    0.133927  \n",
       "JLR     0.019373    0.110520  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2v_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df = pd.DataFrame(list(nx.pagerank(G).items()), columns=[\"gare\", \"PageRank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features to dataframe\n",
    "X = pd.merge(X, centrality_df, on=\"gare\")\n",
    "X = pd.merge(X, neighbor_delay_df, on='gare')\n",
    "X = pd.merge(X, pr_df, on=\"gare\")\n",
    "X.columns\n",
    "X_save = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(X, n2v_df, on=\"gare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['train', 'gare', 'date', 'arret', 'p2q0', 'p3q0', 'p4q0', 'p0q2',\n",
       "       'p0q3', 'p0q4', 'Target', 'centrality', 'neighbor_delay', 'PageRank',\n",
       "       'n2v_dim_0', 'n2v_dim_1', 'n2v_dim_2', 'n2v_dim_3', 'n2v_dim_4',\n",
       "       'n2v_dim_5', 'n2v_dim_6', 'n2v_dim_7', 'n2v_dim_8', 'n2v_dim_9',\n",
       "       'n2v_dim_10', 'n2v_dim_11', 'n2v_dim_12', 'n2v_dim_13', 'n2v_dim_14',\n",
       "       'n2v_dim_15', 'n2v_dim_16', 'n2v_dim_17', 'n2v_dim_18', 'n2v_dim_19',\n",
       "       'n2v_dim_20', 'n2v_dim_21', 'n2v_dim_22', 'n2v_dim_23', 'n2v_dim_24',\n",
       "       'n2v_dim_25', 'n2v_dim_26', 'n2v_dim_27', 'n2v_dim_28', 'n2v_dim_29',\n",
       "       'n2v_dim_30', 'n2v_dim_31'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('sources/x_train_post_engineering.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nouvelles Features:\n",
    "- Centrality: Représente la centralité d'une gare au sein du réseau\n",
    "- neighbor_delay:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.A Neural Network Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 11:01:41.267921: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-27 11:01:41.379445: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-27 11:01:41.417851: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743069701.499147   10831 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743069701.515893   10831 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743069701.645334   10831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743069701.645376   10831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743069701.645379   10831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743069701.645380   10831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-27 11:01:41.651260: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/tmp/ipykernel_10831/3641034499.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.46526721  1.09220326 -1.03902213 ...  0.2397131   0.38179479\n",
      "  0.52387648]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, features] = (X_train[features] - X_train[features].mean()) / X_train[features].std()\n",
      "/tmp/ipykernel_10831/3641034499.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.69507138  0.83797841  0.98088544 ...  0.83797841 -0.59109188\n",
      "  1.40960653]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, features] = (X_test[features] - X_test[features].mean()) / X_test[features].std()\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "# Vars\n",
    "dim = 32\n",
    "\n",
    "# MODEL\n",
    "class mainModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(mainModel,self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(256,activation = 'relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(128,activation = 'relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(64,activation = 'relu')\n",
    "        self.dense4 = tf.keras.layers.Dense(32,activation = 'relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(1,activation = 'linear')\n",
    "    \n",
    "    def get_dense(self,X):\n",
    "        X = self.dense1(X)\n",
    "        X = self.dense2(X)\n",
    "        X = self.dense3(X)\n",
    "        X = self.dense4(X)\n",
    "        return X\n",
    " \n",
    "    def call(self,X):\n",
    "        X = self.get_dense(X)\n",
    "        X = self.output_layer(X)\n",
    "        return X\n",
    "    \n",
    "# CALLBACKS\n",
    "class MAECallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "        mae_score = mae(self.y_val, y_pred)\n",
    "        mlflow.log_metric(\"MAE\", mae_score, step=epoch)\n",
    " \n",
    "# DATA\n",
    "X = pd.read_csv(\"sources/x_train_post_engineering.csv\")\n",
    "Y = pd.read_csv(SOURCES_DIR + \"y_train_final.csv\")\n",
    "X = X.sort_values(by='date')\n",
    "split_index = int(0.8 * len(X))\n",
    "target = X['Target']\n",
    "features = ['arret','p2q0', 'p3q0', 'p4q0', 'p0q2', 'p0q3', 'p0q4', 'centrality', 'neighbor_delay', 'PageRank']\n",
    "for x in range(dim):\n",
    "    features.append(f\"n2v_dim_{x}\")\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "Y_train, Y_test = target[:split_index], target[split_index:]\n",
    "X_train.loc[:, features] = (X_train[features] - X_train[features].mean()) / X_train[features].std()\n",
    "X_test.loc[:, features] = (X_test[features] - X_test[features].mean()) / X_test[features].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "use_mlflow = False\n",
    "num_epochs = 10\n",
    "batch_size = 1000\n",
    "model = mainModel()\n",
    "if use_mlflow:\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    mlflow.set_experiment(\"Embedding Neural Network\")\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"Number of layer\", len(model.layers))\n",
    "        model.compile(optimizer='adamax',\n",
    "                    loss= 'mae',\n",
    "                    metrics=[])\n",
    "        model.fit(X_train[features].values, Y_train.values, \n",
    "                validation_data=(X_test[features], Y_test),\n",
    "                epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                callbacks=[MAECallback(X_test[features], Y_test)])\n",
    "        embedded_layer = model.get_dense(X_train[features].values)\n",
    "else:\n",
    "    model.compile(optimizer='adamax',\n",
    "                    loss= 'mae',\n",
    "                    metrics=[])\n",
    "    model.fit(X_train[features].values, Y_train.values, \n",
    "                validation_data=(X_test[features], Y_test),\n",
    "                epochs=num_epochs,\n",
    "                batch_size=batch_size)\n",
    "    embedded_layer = model.get_dense(X_train[features].values)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.B KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=128, weights='distance')\n",
    "neigh.fit(embedded_layer, Y_train)\n",
    "pred = neigh.predict(model.get_dense(X_test[features]))\n",
    "\n",
    "mae(Y_test, pred)\n",
    "#0.6349923568024458\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = pd.read_csv(SOURCES_DIR + \"x_test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_eval = pd.merge(x_eval, centrality_df, on=\"gare\")\n",
    "x_eval = pd.merge(x_eval, neighbor_delay_df, on='gare')\n",
    "x_eval = pd.merge(x_eval, pr_df, on=\"gare\")\n",
    "x_eval = pd.merge(x_eval, n2v_df, on=\"gare\")\n",
    "x_eval = (x_eval[features] - x_eval[features].mean())/x_eval[features].std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prediction = neigh.predict(model.get_dense(x_eval[features]))\n",
    "prediction = pd.DataFrame(eval_prediction, columns=['p0q0']).to_csv('results/predictionKNN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.C RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_post_FE = RandomForestClassifier(max_depth=18,n_estimators=120, random_state=42, n_jobs=-1, min_samples_split=10, max_features=int(0.3*len(features)))\n",
    "clf_post_FE.fit(embedded_layer, Y_train)\n",
    "pred = clf_post_FE.predict(model.get_dense(X_test[features].values))\n",
    "print(f'MAE Validation: {mae(Y_test, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest Classifier post engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "X = X.sort_values(by='date')\n",
    "split_index = int(0.8 * len(X))\n",
    "target = X['Target']\n",
    "features = ['arret','p2q0', 'p3q0', 'p4q0', 'p0q2', 'p0q3', 'p0q4', 'centrality', 'neighbor_delay', 'PageRank']\n",
    "for x in range(dim):\n",
    "    features.append(f\"n2v_dim_{x}\")\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "Y_train, Y_test = target[:split_index], target[split_index:]\n",
    "#clf_post_FE = RandomForestRegressor(n_estimators = 100, random_state = None,criterion='squared_error',oob_score=True,n_jobs=-1,max_depth=18,min_samples_leaf=5)\n",
    "clf_post_FE = RandomForestClassifier(max_depth=18,n_estimators=120, random_state=42, n_jobs=-1, min_samples_split=10, max_features=int(0.3*len(features)))\n",
    "clf_post_FE.fit(X_train[features], Y_train)\n",
    "pred = clf_post_FE.predict(X_test[features])\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "print(f'MAE Validation: {mae(Y_test, pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = pd.read_csv(SOURCES_DIR + \"x_test_final.csv\").drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = pd.merge(x_eval, centrality_df, on=\"gare\")\n",
    "x_eval = pd.merge(x_eval, neighbor_delay_df, on='gare')\n",
    "x_eval = pd.merge(x_eval, pr_df, on=\"gare\")\n",
    "x_eval = pd.merge(x_eval, n2v_df, on=\"gare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prediction = clf_post_FE.predict(x_eval[features])\n",
    "prediction = pd.DataFrame(eval_prediction, columns=['p0q0']).to_csv('results/predictionRFC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meilleur score sur [challenge-data](https://challengedata.ens.fr/): \n",
    "> GraphicCardEater : 0.6658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"End of notebook!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recherche d'un autre modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"sources/x_train_post_engineering.csv\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.sort_values(by='date')\n",
    "split_index = int(0.8 * len(X))\n",
    "target = X['Target']\n",
    "features = ['arret','p2q0', 'p3q0', 'p4q0', 'p0q2', 'p0q3', 'p0q4', 'centrality', 'neighbor_delay', 'PageRank']\n",
    "for x in range(dim):\n",
    "    features.append(f\"n2v_dim_{x}\")\n",
    "#features = ['arret','p2q0', 'p3q0', 'p4q0', 'p0q2', 'p0q3', 'p0q4']\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "Y_train, Y_test = target[:split_index], target[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_r = xgb.XGBRegressor(objective ='reg:squarederror', \n",
    "                  n_estimators = 120, seed = 42) \n",
    "\n",
    "xgb_r.fit(X_train[features], Y_train) \n",
    "# Predict the model \n",
    "xgb_pred = xgb_r.predict(X_test[features])\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "print(f'MAE Validation: {mae(Y_test, xgb_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train[features], Y_train)\n",
    "gbr_pred = model.predict(X_test[features])\n",
    "print(f'MAE Validation: {mae(Y_test, gbr_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=6, random_state=0, n_init=\"auto\").fit(X_train[features])\n",
    "kmeans.predict(X_test[features])\n",
    "kmeans.cluster_centers_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
